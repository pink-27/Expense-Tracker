input {
  # Monitor logs generated by the backend service
  file {
    path => "/app/logs/*.log"  # Log files inside the mounted volume
    start_position => "beginning"  # Start reading from the beginning for testing
    sincedb_path => "/dev/null"    # Prevent Logstash from keeping track of read positions
  }
}

filter {
  grok {
    match => { 
      "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{DATA:thread}\] %{LOGLEVEL:log_level}\s+%{JAVACLASS:logger} - %{GREEDYDATA:log_message}"
    }
  }

  # Convert the parsed timestamp into Elasticsearch-compatible format
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Optionally tag logs for identification
  mutate {
    add_tag => ["backend_logs"]
  }
}


output {
  # Send logs to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]  # Use the service name 'elasticsearch'
    index => "backend-logs-%{+YYYY.MM.dd}"  # Daily index pattern
  }

  # Debugging: print logs to the console
  stdout {
    codec => rubydebug
  }
}
